{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# set up autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 20\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_classes = ['Main System', 'claps', 'fx/processed sound', 'tuba', 'piccolo', 'cymbal', 'glockenspiel', 'tambourine', 'timpani', 'snare drum', 'clarinet section', 'flute section', 'tenor saxophone', 'trumpet section']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first thing to do is to partition the MDB track IDs and stem IDs into only the ones we will use. \n",
    "import medleydb as mdb\n",
    "\n",
    "mtrack_generator = mdb.load_all_multitracks(['V1', 'V2'])\n",
    "splits = mdb.utils.artist_conditional_split(test_size=TEST_SIZE, num_splits=1, \n",
    "                                            random_state=RANDOM_SEED)[0]\n",
    "partition_map = {}\n",
    "\n",
    "for mtrack in mtrack_generator:\n",
    "\n",
    "    # add appropriate partition key for this mtrack\n",
    "    if mtrack.track_id in splits['test']:\n",
    "        partition_key = 'test'\n",
    "    elif mtrack.track_id in splits['train']:\n",
    "        partition_key = 'train'\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # add the partition dict if we havent yet\n",
    "    if partition_key not in partition_map:\n",
    "        partition_map[partition_key] = []\n",
    "    \n",
    "    # shorten name so we don't have to call\n",
    "    # the very nested dict every time\n",
    "    partition_list = partition_map[partition_key]\n",
    "\n",
    "    # iterate through the stems in this mtrack\n",
    "    for stem_id, stem in mtrack.stems.items():\n",
    "        label = stem.instrument[0]\n",
    "        \n",
    "        # continue if we don't want this class\n",
    "        if label in unwanted_classes:\n",
    "            continue\n",
    "\n",
    "        # append the stem with it's corresponding info\n",
    "        stem_info = dict(track_id=mtrack.track_id, stem_idx=stem.stem_idx, \n",
    "                         label=label, \n",
    "                         artist_id=mtrack.track_id.split('_')[0], \n",
    "                         path_to_audio=stem.audio_path, \n",
    "                         base_chunk_name=f'{mtrack.track_id}-{stem_id}-{label}')\n",
    "        partition_list.append(stem_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22\n22\n"
     ]
    }
   ],
   "source": [
    "import instrument_recognition.utils as utils\n",
    "# get the unique set of classes for both partition\n",
    "classlists = {k: utils.data.get_classlist(metadata) for k, metadata in partition_map.items()}\n",
    "\n",
    "# filter classes so we only have the intersection of the two sets :)\n",
    "filtered_classes = list(set(classlists['train']) & set(classlists['test']))\n",
    "\n",
    "# filter out the partition map!!!\n",
    "for partition_key, metadata in partition_map.items():\n",
    "    partition_map[partition_key] = [e for e in metadata if e['label'] in  filtered_classes]\n",
    "\n",
    "print(len(utils.data.get_classlist(partition_map['train'])))\n",
    "print(len(utils.data.get_classlist(partition_map['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1\n",
    "SR = 48000\n",
    "HOP_SIZE = 0.25 \n",
    "AUGMENT_TRAIN_SET = True\n",
    "PATH_TO_OUTPUT = f'/home/hugo/data/mono_music_sed/mdb/AUDIO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=85.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1ea7a32ed7948e89b86f34c9fb6408a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=504.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcb167811f7d448e9d543b370c30fde3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "exception occured: Error reading audio file: unknown length\n",
      "FAILED TO LOAD: /home/hugo/data/medleydb/Audio/EthanHein_HarmonicaFigure/EthanHein_HarmonicaFigure_STEMS/EthanHein_HarmonicaFigure_STEM_04.wav\n",
      "exception occured: Error reading audio file: unknown length\n",
      "FAILED TO LOAD: /home/hugo/data/medleydb/Audio/FacesOnFilm_WaitingForGa/FacesOnFilm_WaitingForGa_STEMS/FacesOnFilm_WaitingForGa_STEM_11.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from instrument_recognition.scripts.generate_dataset import save_windowed_audio_events, load_audio_file, trim_silence\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# now, save and do the magic\n",
    "for partition_key, metadata in partition_map.items():\n",
    "    augment = True if partition_key == 'train' else False\n",
    "\n",
    "    def split_and_augment(entry):\n",
    "        try:\n",
    "            path_to_audio = entry['path_to_audio']\n",
    "            base_chunk_name = entry['base_chunk_name']\n",
    "            label = entry['label']\n",
    "            output_path = os.path.join(PATH_TO_OUTPUT, partition_key)\n",
    "\n",
    "            audio = load_audio_file(path_to_audio, SR)\n",
    "            # trim silence\n",
    "            audio = trim_silence(audio, SR, min_silence_duration=0.3)\n",
    "\n",
    "            save_windowed_audio_events(audio=audio, sr=SR, chunk_size=CHUNK_SIZE, \n",
    "                                    hop_size=HOP_SIZE, base_chunk_name=base_chunk_name, \n",
    "                                    label=label, path_to_output=output_path, \n",
    "                                    metadata_extras=entry, augment=True)\n",
    "        except Exception as e:\n",
    "            print(f'exception occured: {e}')\n",
    "            print(f'FAILED TO LOAD: {path_to_audio}')\n",
    "\n",
    "    # DO IT IN PARALLEL\n",
    "    tqdm.contrib.concurrent.process_map(split_and_augment, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}