{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Instrument Detection Models\n",
    "\n",
    "11/30/2020\n",
    "\n",
    "Evaluation Metrics: F1 score, Expected Calibration Error (ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths to datamodules \n",
    "dm_paths = {\n",
    "    'audio': \n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED/splits-85-15', \n",
    "    \n",
    "    'embeddings-512': \n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED-EMBEDDINGS-512/splits-85-15', \n",
    "\n",
    "    'embeddings-6144':\n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED-EMBEDDINGS-6144/splits-85-15'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "now = datetime.datetime.now().strftime(\"%d.%m.%Y-%H.%M.%S\")\n",
    "log_dir = os.path.join('logs', f'experiment-{now}')\n",
    "# define experiment\n",
    "FIXED = dict(\n",
    "    batch_size=128*3,\n",
    "    num_workers=20,\n",
    "\n",
    "    learning_rate=3e-4,\n",
    "    weighted_cross_entropy=True,\n",
    "\n",
    "    dropout=0.5,\n",
    "    random_seed=20, \n",
    "    max_epochs=80, \n",
    "    log_dir=log_dir,\n",
    "    \n",
    "    version=0, \n",
    "    gpuid=-1\n",
    ")\n",
    "\n",
    "trials = [\n",
    "    # EFFECTIVE RISK MINIMIZATION (NO MIXUP)\n",
    "    dict(name='openl3-512-mlp-ERM',\n",
    "        path_to_data=dm_paths['embeddings-512'],\n",
    "        use_embeddings= True, \n",
    "        model_name='mlp-512',\n",
    "        mixup=False,\n",
    "        mixup_alpha=0), \n",
    "\n",
    "    dict(name='openl3-6144-mlp-ERM',\n",
    "        path_to_data=dm_paths['embeddings-6144'],\n",
    "        use_embeddings= True, \n",
    "        model_name='mlp-6144',\n",
    "        mixup=False,\n",
    "        mixup_alpha=0), \n",
    "    \n",
    "#     dict(name='baseline-512-mlp-ERM', \n",
    "#          path_to_data=dm_paths['audio'],\n",
    "#          batch_size=48*3,\n",
    "#          use_embeddings=False, \n",
    "#          model_name='baseline-512', \n",
    "#          mixup=False, \n",
    "#          mixup_alpha=0),\n",
    "    \n",
    "    dict(name='baseline-6144-mlp-ERM', \n",
    "         path_to_data=dm_paths['audio'], \n",
    "         batch_size=48*3,\n",
    "         use_embeddings=False, \n",
    "         model_name='baseline-6144', \n",
    "         mixup=False, \n",
    "         mixup_alpha=0),\n",
    "    \n",
    "    # MODELS WITH MIXUP (ALPHA = 0.2)\n",
    "#     dict(name='openl3-512-mlp-MIXUP-alpha=0.2',\n",
    "#         path_to_data=dm_paths['embeddings-512'],\n",
    "#         use_embeddings= True, \n",
    "#         model_name='mlp-512',\n",
    "#         mixup=True,\n",
    "#         mixup_alpha=0.2),\n",
    "\n",
    "    dict(name='openl3-6144-mlp-MIXUP-alpha=0.2',\n",
    "        path_to_data=dm_paths['embeddings-6144'],\n",
    "        use_embeddings= True, \n",
    "        model_name='mlp-6144',\n",
    "        mixup=True,\n",
    "        mixup_alpha=0.2),\n",
    "    \n",
    "    # MODELS WITH MIXUP (ALPHA = 0.4)\n",
    "#     dict(name='openl3-512-mlp-MIXUP-alpha=0.4',\n",
    "#         path_to_data=dm_paths['embeddings-512'],\n",
    "#         use_embeddings= True, \n",
    "#         model_name='mlp-512',\n",
    "#         mixup=True,\n",
    "#         mixup_alpha=0.2),\n",
    "    \n",
    "    dict(name='openl3-6144-mlp-MIXUP-alpha=0.4',\n",
    "        path_to_data=dm_paths['embeddings-6144'],\n",
    "        use_embeddings= True, \n",
    "        model_name='mlp-6144',\n",
    "        mixup=True,\n",
    "        mixup_alpha=0.4)]\n",
    "\n",
    "exp_dicts = [dict(FIXED) for t in trials]\n",
    "for exp, t in zip(exp_dicts, trials):\n",
    "    exp.update(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/lab/venv/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from instrument_recognition.task import load_datamodule, load_model, InstrumentDetectionTask, train_instrument_detection_model\n",
    "\n",
    "def run_trial(exp_dict):\n",
    "\n",
    "    # load the datamodule\n",
    "    print(f'loading datamodule...')\n",
    "    dm = load_datamodule(path_to_data=exp_dict['path_to_data'], \n",
    "                         batch_size=exp_dict['batch_size'], \n",
    "                         num_workers=exp_dict['num_workers'],\n",
    "                         use_embeddings=exp_dict['use_embeddings'])\n",
    "    \n",
    "    # get classlist and number of classes\n",
    "    classlist = dm.get_classes()\n",
    "    num_output_units = len(classlist)\n",
    "    print(f'classlist is: {classlist}')\n",
    "\n",
    "    # load model\n",
    "    print(f'loading model...')\n",
    "    model = load_model(model_name=exp_dict['model_name'], \n",
    "                       output_units=num_output_units, \n",
    "                       dropout=exp_dict['dropout'])\n",
    "    \n",
    "    # build task\n",
    "    print(f'building task...')\n",
    "    task = InstrumentDetectionTask(model, dm, \n",
    "                            max_epochs=exp_dict['max_epochs'],\n",
    "                            learning_rate=exp_dict['learning_rate'], \n",
    "                            weighted_cross_entropy=exp_dict['weighted_cross_entropy'], \n",
    "                            mixup=exp_dict['mixup'],\n",
    "                            mixup_alpha=exp_dict['mixup_alpha'], \n",
    "                            log_epoch_metrics=True)\n",
    "    \n",
    "    # run train fn and get back test results\n",
    "    print(f'running task')\n",
    "    result = train_instrument_detection_model(task, \n",
    "                                    name=exp_dict['name'], \n",
    "                                    version=exp_dict['version'], \n",
    "                                    gpuid=exp_dict['gpuid'], \n",
    "                                    max_epochs=exp_dict['max_epochs'],\n",
    "                                    random_seed=exp_dict['random_seed'], \n",
    "                                    log_dir=exp_dict['log_dir'],)\n",
    "    \n",
    "    result = result[0]\n",
    "\n",
    "    result['done'] = True\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name       | Type        | Params\n",
      "-------------------------------------------\n",
      "0 | model      | MLP512      | 69 K  \n",
      "1 | model.fc   | Sequential  | 69 K  \n",
      "2 | model.fc.0 | BatchNorm1d | 1 K   \n",
      "3 | model.fc.1 | Linear      | 65 K  \n",
      "4 | model.fc.2 | ReLU        | 0     \n",
      "5 | model.fc.3 | Dropout     | 0     \n",
      "6 | model.fc.4 | BatchNorm1d | 256   \n",
      "7 | model.fc.5 | Linear      | 2 K   \n",
      "Epoch 0: loss/val reached 1.29530 (best 1.29530), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=00-loss_val=1.29.ckpt as top 3\n",
      "Epoch 1: loss/val reached 1.33528 (best 1.29530), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=01-loss_val=1.34.ckpt as top 3\n",
      "Epoch 2: loss/val reached 1.28165 (best 1.28165), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=02-loss_val=1.29.ckpt as top 3\n",
      "Epoch 3: loss/val reached 1.32449 (best 1.28165), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=03-loss_val=1.33.ckpt as top 3\n",
      "Epoch 4: loss/val was not in top 3\n",
      "Epoch 5: loss/val reached 1.32292 (best 1.28165), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=05-loss_val=1.33.ckpt as top 3\n",
      "Epoch 6: loss/val reached 1.29819 (best 1.28165), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=06-loss_val=1.26.ckpt as top 3\n",
      "Epoch 7: loss/val was not in top 3\n",
      "Epoch 8: loss/val was not in top 3\n",
      "Epoch 9: loss/val was not in top 3\n",
      "Epoch 10: loss/val was not in top 3\n",
      "Epoch 11: loss/val was not in top 3\n",
      "Epoch 12: loss/val was not in top 3\n",
      "Epoch 13: loss/val was not in top 3\n",
      "Epoch 14: loss/val was not in top 3\n",
      "Epoch 15: loss/val was not in top 3\n",
      "Epoch 16: loss/val was not in top 3\n",
      "Epoch 17: loss/val was not in top 3\n",
      "Epoch 18: loss/val was not in top 3\n",
      "Epoch 19: loss/val was not in top 3\n",
      "Epoch 20: loss/val was not in top 3\n",
      "Epoch 21: loss/val was not in top 3\n",
      "Epoch 22: loss/val was not in top 3\n",
      "Epoch 23: loss/val was not in top 3\n",
      "Epoch 24: loss/val was not in top 3\n",
      "Epoch 25: loss/val was not in top 3\n",
      "Epoch 26: loss/val was not in top 3\n",
      "Epoch 27: loss/val was not in top 3\n",
      "Epoch 28: loss/val was not in top 3\n",
      "Epoch 29: loss/val was not in top 3\n",
      "Epoch 30: loss/val was not in top 3\n",
      "Epoch 31: loss/val was not in top 3\n",
      "Epoch 32: loss/val was not in top 3\n",
      "Epoch 33: loss/val was not in top 3\n",
      "Epoch 34: loss/val was not in top 3\n",
      "Epoch 35: loss/val was not in top 3\n",
      "Epoch 36: loss/val was not in top 3\n",
      "Epoch 37: loss/val was not in top 3\n",
      "Epoch 38: loss/val was not in top 3\n",
      "Epoch 39: loss/val was not in top 3\n",
      "Epoch 40: loss/val was not in top 3\n",
      "Epoch 41: loss/val was not in top 3\n",
      "Epoch 42: loss/val was not in top 3\n",
      "Epoch 43: loss/val was not in top 3\n",
      "Epoch 44: loss/val was not in top 3\n",
      "Epoch 45: loss/val was not in top 3\n",
      "Epoch 46: loss/val was not in top 3\n",
      "Epoch 47: loss/val was not in top 3\n",
      "Epoch 48: loss/val was not in top 3\n",
      "Epoch 49: loss/val was not in top 3\n",
      "Epoch 50: loss/val was not in top 3\n",
      "Epoch 51: loss/val was not in top 3\n",
      "Epoch 52: loss/val was not in top 3\n",
      "Epoch 53: loss/val was not in top 3\n",
      "Epoch 54: loss/val was not in top 3\n",
      "Epoch 55: loss/val was not in top 3\n",
      "Epoch 56: loss/val was not in top 3\n",
      "Epoch 57: loss/val was not in top 3\n",
      "Epoch 58: loss/val was not in top 3\n",
      "Epoch 59: loss/val reached 1.27160 (best 1.27160), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-512-mlp-ERM/version_0/checkpoints/epoch=59-loss_val=1.27.ckpt as top 3\n",
      "Epoch 60: loss/val was not in top 3\n",
      "Epoch 61: loss/val was not in top 3\n",
      "Epoch 62: loss/val was not in top 3\n",
      "Epoch 63: loss/val was not in top 3\n",
      "Epoch 64: loss/val was not in top 3\n",
      "Epoch 65: loss/val was not in top 3\n",
      "Epoch 66: loss/val was not in top 3\n",
      "Epoch 67: loss/val was not in top 3\n",
      "Epoch 68: loss/val was not in top 3\n",
      "Epoch 69: loss/val was not in top 3\n",
      "Epoch 70: loss/val was not in top 3\n",
      "Epoch 71: loss/val was not in top 3\n",
      "Epoch 72: loss/val was not in top 3\n",
      "Epoch 73: loss/val was not in top 3\n",
      "Epoch 74: loss/val was not in top 3\n",
      "Epoch 75: loss/val was not in top 3\n",
      "Epoch 76: loss/val was not in top 3\n",
      "Epoch 77: loss/val was not in top 3\n",
      "Epoch 78: loss/val was not in top 3\n",
      "Epoch 79: loss/val was not in top 3\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_fit_start        \t|  2.964e-05      \t|  2.964e-05      \n",
      "on_train_start      \t|  0.016788       \t|  0.016788       \n",
      "on_epoch_start      \t|  0.0027847      \t|  0.22278        \n",
      "on_train_epoch_start\t|  1.4209e-05     \t|  0.0011367      \n",
      "get_train_batch     \t|  0.0087832      \t|  528.4          \n",
      "on_batch_start      \t|  3.9993e-05     \t|  2.406          \n",
      "on_train_batch_start\t|  2.0434e-05     \t|  1.2293         \n",
      "training_step_end   \t|  0.00012238     \t|  7.3623         \n",
      "model_forward       \t|  0.036675       \t|  2206.4         \n",
      "model_backward      \t|  0.0045833      \t|  275.73         \n",
      "on_after_backward   \t|  2.7082e-05     \t|  1.6292         \n",
      "optimizer_step      \t|  0.045628       \t|  2745.0         \n",
      "on_batch_end        \t|  3.3827e-05     \t|  2.035          \n",
      "on_train_batch_end  \t|  0.0023405      \t|  140.8          \n",
      "on_validation_start \t|  0.026693       \t|  2.1354         \n",
      "on_validation_epoch_start\t|  2.6589e-05     \t|  0.0021271      \n",
      "on_validation_batch_start\t|  3.825e-05      \t|  0.44983        \n",
      "validation_step_end \t|  4.6e-05        \t|  0.54096        \n",
      "on_validation_batch_end\t|  0.0012921      \t|  15.195         \n",
      "on_validation_epoch_end\t|  0.00011846     \t|  0.0094772      \n",
      "on_validation_end   \t|  0.0075516      \t|  0.60413        \n",
      "on_epoch_end        \t|  0.00011866     \t|  0.0094932      \n",
      "on_train_epoch_end  \t|  4.2181e-05     \t|  0.0033745      \n",
      "on_train_end        \t|  0.0018222      \t|  0.0018222      \n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name       | Type        | Params\n",
      "--------------------------------------------\n",
      "0  | model      | MLP6144     | 3 M   \n",
      "1  | model.fc   | Sequential  | 3 M   \n",
      "2  | model.fc.0 | BatchNorm1d | 12 K  \n",
      "3  | model.fc.1 | Linear      | 3 M   \n",
      "4  | model.fc.2 | ReLU        | 0     \n",
      "5  | model.fc.3 | Dropout     | 0     \n",
      "6  | model.fc.4 | BatchNorm1d | 1 K   \n",
      "7  | model.fc.5 | Linear      | 65 K  \n",
      "8  | model.fc.6 | ReLU        | 0     \n",
      "9  | model.fc.7 | Dropout     | 0     \n",
      "10 | model.fc.8 | BatchNorm1d | 256   \n",
      "11 | model.fc.9 | Linear      | 2 K   \n",
      "Epoch 0: loss/val reached 1.19397 (best 1.19397), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-ERM/version_0/checkpoints/epoch=00-loss_val=1.20.ckpt as top 3\n",
      "Epoch 1: loss/val reached 1.29360 (best 1.19397), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-ERM/version_0/checkpoints/epoch=01-loss_val=1.29.ckpt as top 3\n",
      "Epoch 2: loss/val reached 1.42312 (best 1.19397), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-ERM/version_0/checkpoints/epoch=02-loss_val=1.43.ckpt as top 3\n",
      "Epoch 3: loss/val reached 1.27953 (best 1.19397), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-ERM/version_0/checkpoints/epoch=03-loss_val=1.28.ckpt as top 3\n",
      "Epoch 4: loss/val was not in top 3\n",
      "Epoch 5: loss/val was not in top 3\n",
      "Epoch 6: loss/val was not in top 3\n",
      "Epoch 7: loss/val was not in top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: loss/val was not in top 3\n",
      "Epoch 9: loss/val was not in top 3\n",
      "Epoch 10: loss/val was not in top 3\n",
      "Epoch 11: loss/val was not in top 3\n",
      "Epoch 12: loss/val was not in top 3\n",
      "Epoch 13: loss/val was not in top 3\n",
      "Epoch 14: loss/val was not in top 3\n",
      "Epoch 15: loss/val was not in top 3\n",
      "Epoch 16: loss/val was not in top 3\n",
      "Epoch 17: loss/val was not in top 3\n",
      "Epoch 18: loss/val was not in top 3\n",
      "Epoch 19: loss/val was not in top 3\n",
      "Epoch 20: loss/val was not in top 3\n",
      "Epoch 21: loss/val was not in top 3\n",
      "Epoch 22: loss/val was not in top 3\n",
      "Epoch 23: loss/val was not in top 3\n",
      "Epoch 24: loss/val was not in top 3\n",
      "Epoch 25: loss/val was not in top 3\n",
      "Epoch 26: loss/val was not in top 3\n",
      "Epoch 27: loss/val was not in top 3\n",
      "Epoch 28: loss/val was not in top 3\n",
      "Epoch 29: loss/val was not in top 3\n",
      "Epoch 30: loss/val was not in top 3\n",
      "Epoch 31: loss/val was not in top 3\n",
      "Epoch 32: loss/val was not in top 3\n",
      "Epoch 33: loss/val was not in top 3\n",
      "Epoch 34: loss/val was not in top 3\n",
      "Epoch 35: loss/val was not in top 3\n",
      "Epoch 36: loss/val was not in top 3\n",
      "Epoch 37: loss/val was not in top 3\n",
      "Epoch 38: loss/val was not in top 3\n",
      "Epoch 39: loss/val was not in top 3\n",
      "Epoch 40: loss/val was not in top 3\n",
      "Epoch 41: loss/val was not in top 3\n",
      "Epoch 42: loss/val was not in top 3\n",
      "Epoch 43: loss/val was not in top 3\n",
      "Epoch 44: loss/val was not in top 3\n",
      "Epoch 45: loss/val was not in top 3\n",
      "Epoch 46: loss/val was not in top 3\n",
      "Epoch 47: loss/val was not in top 3\n",
      "Epoch 48: loss/val was not in top 3\n",
      "Epoch 49: loss/val was not in top 3\n",
      "Epoch 50: loss/val was not in top 3\n",
      "Epoch 51: loss/val was not in top 3\n",
      "Epoch 52: loss/val was not in top 3\n",
      "Epoch 53: loss/val was not in top 3\n",
      "Epoch 54: loss/val was not in top 3\n",
      "Epoch 55: loss/val was not in top 3\n",
      "Epoch 56: loss/val was not in top 3\n",
      "Epoch 57: loss/val was not in top 3\n",
      "Epoch 58: loss/val was not in top 3\n",
      "Epoch 59: loss/val was not in top 3\n",
      "Epoch 60: loss/val was not in top 3\n",
      "Epoch 61: loss/val was not in top 3\n",
      "Epoch 62: loss/val was not in top 3\n",
      "Epoch 63: loss/val was not in top 3\n",
      "Epoch 64: loss/val was not in top 3\n",
      "Epoch 65: loss/val was not in top 3\n",
      "Epoch 66: loss/val was not in top 3\n",
      "Epoch 67: loss/val was not in top 3\n",
      "Epoch 68: loss/val was not in top 3\n",
      "Epoch 69: loss/val was not in top 3\n",
      "Epoch 70: loss/val was not in top 3\n",
      "Epoch 71: loss/val was not in top 3\n",
      "Epoch 72: loss/val was not in top 3\n",
      "Epoch 73: loss/val was not in top 3\n",
      "Epoch 74: loss/val was not in top 3\n",
      "Epoch 75: loss/val was not in top 3\n",
      "Epoch 76: loss/val was not in top 3\n",
      "Epoch 77: loss/val was not in top 3\n",
      "Epoch 78: loss/val was not in top 3\n",
      "Epoch 79: loss/val was not in top 3\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_fit_start        \t|  2.2023e-05     \t|  2.2023e-05     \n",
      "on_train_start      \t|  0.015674       \t|  0.015674       \n",
      "on_epoch_start      \t|  0.0026178      \t|  0.20942        \n",
      "on_train_epoch_start\t|  1.3621e-05     \t|  0.0010897      \n",
      "get_train_batch     \t|  0.021241       \t|  1277.9         \n",
      "on_batch_start      \t|  4.0428e-05     \t|  2.4321         \n",
      "on_train_batch_start\t|  1.9829e-05     \t|  1.1929         \n",
      "training_step_end   \t|  0.0001227      \t|  7.3814         \n",
      "model_forward       \t|  0.038734       \t|  2330.3         \n",
      "model_backward      \t|  0.0059858      \t|  360.1          \n",
      "on_after_backward   \t|  2.8363e-05     \t|  1.7063         \n",
      "optimizer_step      \t|  0.050672       \t|  3048.4         \n",
      "on_batch_end        \t|  3.2077e-05     \t|  1.9298         \n",
      "on_train_batch_end  \t|  0.0021928      \t|  131.92         \n",
      "on_validation_start \t|  0.024483       \t|  1.9586         \n",
      "on_validation_epoch_start\t|  2.742e-05      \t|  0.0021936      \n",
      "on_validation_batch_start\t|  4.0149e-05     \t|  0.47216        \n",
      "validation_step_end \t|  4.5541e-05     \t|  0.53556        \n",
      "on_validation_batch_end\t|  0.0013719      \t|  16.133         \n",
      "on_validation_epoch_end\t|  0.00012218     \t|  0.009774       \n",
      "on_validation_end   \t|  0.011769       \t|  0.94154        \n",
      "on_epoch_end        \t|  0.0001157      \t|  0.0092562      \n",
      "on_train_epoch_end  \t|  3.7747e-05     \t|  0.0030198      \n",
      "on_train_end        \t|  0.0024531      \t|  0.0024531      \n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name                                      | Type            | Params\n",
      "-------------------------------------------------------------------------------\n",
      "0  | model                                     | OpenL3MLP       | 12 M  \n",
      "1  | model.openl3                              | OpenL3Embedding | 9 M   \n",
      "2  | model.openl3.filters                      | Melspectrogram  | 4 M   \n",
      "3  | model.openl3.filters.conv1d_real          | Conv1d          | 2 M   \n",
      "4  | model.openl3.filters.conv1d_imag          | Conv1d          | 2 M   \n",
      "5  | model.openl3.filters.freq2mel             | Linear          | 262 K \n",
      "6  | model.openl3.openl3                       | OpenL3Mel128    | 4 M   \n",
      "7  | model.openl3.openl3.batch_normalization_1 | BatchNorm2d     | 2     \n",
      "8  | model.openl3.openl3.conv2d_1              | Conv2d          | 640   \n",
      "9  | model.openl3.openl3.batch_normalization_2 | BatchNorm2d     | 128   \n",
      "10 | model.openl3.openl3.conv2d_2              | Conv2d          | 36 K  \n",
      "11 | model.openl3.openl3.batch_normalization_3 | BatchNorm2d     | 128   \n",
      "12 | model.openl3.openl3.conv2d_3              | Conv2d          | 73 K  \n",
      "13 | model.openl3.openl3.batch_normalization_4 | BatchNorm2d     | 256   \n",
      "14 | model.openl3.openl3.conv2d_4              | Conv2d          | 147 K \n",
      "15 | model.openl3.openl3.batch_normalization_5 | BatchNorm2d     | 256   \n",
      "16 | model.openl3.openl3.conv2d_5              | Conv2d          | 295 K \n",
      "17 | model.openl3.openl3.batch_normalization_6 | BatchNorm2d     | 512   \n",
      "18 | model.openl3.openl3.conv2d_6              | Conv2d          | 590 K \n",
      "19 | model.openl3.openl3.batch_normalization_7 | BatchNorm2d     | 512   \n",
      "20 | model.openl3.openl3.conv2d_7              | Conv2d          | 1 M   \n",
      "21 | model.openl3.openl3.batch_normalization_8 | BatchNorm2d     | 1 K   \n",
      "22 | model.openl3.openl3.audio_embedding_layer | Conv2d          | 2 M   \n",
      "23 | model.openl3.openl3.maxpool               | MaxPool2d       | 0     \n",
      "24 | model.openl3.flatten                      | Flatten         | 0     \n",
      "25 | model.mlp                                 | MLP6144         | 3 M   \n",
      "26 | model.mlp.fc                              | Sequential      | 3 M   \n",
      "27 | model.mlp.fc.0                            | BatchNorm1d     | 12 K  \n",
      "28 | model.mlp.fc.1                            | Linear          | 3 M   \n",
      "29 | model.mlp.fc.2                            | ReLU            | 0     \n",
      "30 | model.mlp.fc.3                            | Dropout         | 0     \n",
      "31 | model.mlp.fc.4                            | BatchNorm1d     | 1 K   \n",
      "32 | model.mlp.fc.5                            | Linear          | 65 K  \n",
      "33 | model.mlp.fc.6                            | ReLU            | 0     \n",
      "34 | model.mlp.fc.7                            | Dropout         | 0     \n",
      "35 | model.mlp.fc.8                            | BatchNorm1d     | 256   \n",
      "36 | model.mlp.fc.9                            | Linear          | 2 K   \n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name       | Type        | Params\n",
      "--------------------------------------------\n",
      "0  | model      | MLP6144     | 3 M   \n",
      "1  | model.fc   | Sequential  | 3 M   \n",
      "2  | model.fc.0 | BatchNorm1d | 12 K  \n",
      "3  | model.fc.1 | Linear      | 3 M   \n",
      "4  | model.fc.2 | ReLU        | 0     \n",
      "5  | model.fc.3 | Dropout     | 0     \n",
      "6  | model.fc.4 | BatchNorm1d | 1 K   \n",
      "7  | model.fc.5 | Linear      | 65 K  \n",
      "8  | model.fc.6 | ReLU        | 0     \n",
      "9  | model.fc.7 | Dropout     | 0     \n",
      "10 | model.fc.8 | BatchNorm1d | 256   \n",
      "11 | model.fc.9 | Linear      | 2 K   \n",
      "Epoch 0: loss/val reached 1.29144 (best 1.29144), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=00-loss_val=1.29.ckpt as top 3\n",
      "Epoch 1: loss/val reached 1.29860 (best 1.29144), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=01-loss_val=1.30.ckpt as top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss/val reached 1.30627 (best 1.29144), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=02-loss_val=1.31.ckpt as top 3\n",
      "Epoch 3: loss/val reached 1.29252 (best 1.29144), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=03-loss_val=1.29.ckpt as top 3\n",
      "Epoch 4: loss/val reached 1.24562 (best 1.24562), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=04-loss_val=1.25.ckpt as top 3\n",
      "Epoch 5: loss/val reached 1.29132 (best 1.24562), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=05-loss_val=1.29.ckpt as top 3\n",
      "Epoch 6: loss/val was not in top 3\n",
      "Epoch 7: loss/val was not in top 3\n",
      "Epoch 8: loss/val was not in top 3\n",
      "Epoch 9: loss/val was not in top 3\n",
      "Epoch 10: loss/val reached 1.23563 (best 1.23563), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=10-loss_val=1.24.ckpt as top 3\n",
      "Epoch 11: loss/val reached 1.27030 (best 1.23563), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=11-loss_val=1.29.ckpt as top 3\n",
      "Epoch 12: loss/val was not in top 3\n",
      "Epoch 13: loss/val reached 1.21540 (best 1.21540), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=13-loss_val=1.22.ckpt as top 3\n",
      "Epoch 14: loss/val reached 1.20417 (best 1.20417), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=14-loss_val=1.20.ckpt as top 3\n",
      "Epoch 15: loss/val was not in top 3\n",
      "Epoch 16: loss/val was not in top 3\n",
      "Epoch 17: loss/val was not in top 3\n",
      "Epoch 18: loss/val was not in top 3\n",
      "Epoch 19: loss/val was not in top 3\n",
      "Epoch 20: loss/val was not in top 3\n",
      "Epoch 21: loss/val was not in top 3\n",
      "Epoch 22: loss/val was not in top 3\n",
      "Epoch 23: loss/val was not in top 3\n",
      "Epoch 24: loss/val reached 1.21681 (best 1.20417), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=24-loss_val=1.23.ckpt as top 3\n",
      "Epoch 25: loss/val was not in top 3\n",
      "Epoch 26: loss/val was not in top 3\n",
      "Epoch 27: loss/val was not in top 3\n",
      "Epoch 28: loss/val was not in top 3\n",
      "Epoch 29: loss/val was not in top 3\n",
      "Epoch 30: loss/val was not in top 3\n",
      "Epoch 31: loss/val was not in top 3\n",
      "Epoch 32: loss/val reached 1.20582 (best 1.20417), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=32-loss_val=1.21.ckpt as top 3\n",
      "Epoch 33: loss/val was not in top 3\n",
      "Epoch 34: loss/val was not in top 3\n",
      "Epoch 35: loss/val reached 1.18480 (best 1.18480), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=35-loss_val=1.17.ckpt as top 3\n",
      "Epoch 36: loss/val was not in top 3\n",
      "Epoch 37: loss/val was not in top 3\n",
      "Epoch 38: loss/val was not in top 3\n",
      "Epoch 39: loss/val was not in top 3\n",
      "Epoch 40: loss/val was not in top 3\n",
      "Epoch 41: loss/val was not in top 3\n",
      "Epoch 42: loss/val was not in top 3\n",
      "Epoch 43: loss/val was not in top 3\n",
      "Epoch 44: loss/val was not in top 3\n",
      "Epoch 45: loss/val was not in top 3\n",
      "Epoch 46: loss/val was not in top 3\n",
      "Epoch 47: loss/val was not in top 3\n",
      "Epoch 48: loss/val was not in top 3\n",
      "Epoch 49: loss/val was not in top 3\n",
      "Epoch 50: loss/val was not in top 3\n",
      "Epoch 51: loss/val was not in top 3\n",
      "Epoch 52: loss/val was not in top 3\n",
      "Epoch 53: loss/val was not in top 3\n",
      "Epoch 54: loss/val was not in top 3\n",
      "Epoch 55: loss/val was not in top 3\n",
      "Epoch 56: loss/val was not in top 3\n",
      "Epoch 57: loss/val was not in top 3\n",
      "Epoch 58: loss/val was not in top 3\n",
      "Epoch 59: loss/val was not in top 3\n",
      "Epoch 60: loss/val was not in top 3\n",
      "Epoch 61: loss/val was not in top 3\n",
      "Epoch 62: loss/val was not in top 3\n",
      "Epoch 63: loss/val was not in top 3\n",
      "Epoch 64: loss/val was not in top 3\n",
      "Epoch 65: loss/val was not in top 3\n",
      "Epoch 66: loss/val was not in top 3\n",
      "Epoch 67: loss/val was not in top 3\n",
      "Epoch 68: loss/val was not in top 3\n",
      "Epoch 69: loss/val was not in top 3\n",
      "Epoch 70: loss/val was not in top 3\n",
      "Epoch 71: loss/val was not in top 3\n",
      "Epoch 72: loss/val was not in top 3\n",
      "Epoch 73: loss/val was not in top 3\n",
      "Epoch 74: loss/val was not in top 3\n",
      "Epoch 75: loss/val was not in top 3\n",
      "Epoch 76: loss/val was not in top 3\n",
      "Epoch 77: loss/val reached 1.19755 (best 1.18480), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.2/version_0/checkpoints/epoch=77-loss_val=1.20.ckpt as top 3\n",
      "Epoch 78: loss/val was not in top 3\n",
      "Epoch 79: loss/val was not in top 3\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_fit_start        \t|  2.1783e-05     \t|  2.1783e-05     \n",
      "on_train_start      \t|  0.015976       \t|  0.015976       \n",
      "on_epoch_start      \t|  0.0028893      \t|  0.23114        \n",
      "on_train_epoch_start\t|  1.3451e-05     \t|  0.0010761      \n",
      "get_train_batch     \t|  0.022451       \t|  1350.7         \n",
      "on_batch_start      \t|  4.0649e-05     \t|  2.4454         \n",
      "on_train_batch_start\t|  1.9862e-05     \t|  1.1949         \n",
      "training_step_end   \t|  0.0001237      \t|  7.4416         \n",
      "model_forward       \t|  0.039633       \t|  2384.3         \n",
      "model_backward      \t|  0.006142       \t|  369.5          \n",
      "on_after_backward   \t|  2.846e-05      \t|  1.7121         \n",
      "optimizer_step      \t|  0.051738       \t|  3112.6         \n",
      "on_batch_end        \t|  3.1967e-05     \t|  1.9231         \n",
      "on_train_batch_end  \t|  0.0021969      \t|  132.17         \n",
      "on_validation_start \t|  0.024888       \t|  1.991          \n",
      "on_validation_epoch_start\t|  2.6708e-05     \t|  0.0021367      \n",
      "on_validation_batch_start\t|  4.0154e-05     \t|  0.47221        \n",
      "validation_step_end \t|  4.5407e-05     \t|  0.53398        \n",
      "on_validation_batch_end\t|  0.0013544      \t|  15.928         \n",
      "on_validation_epoch_end\t|  0.00012696     \t|  0.010157       \n",
      "on_validation_end   \t|  0.02589        \t|  2.0712         \n",
      "on_epoch_end        \t|  0.0001176      \t|  0.0094077      \n",
      "on_train_epoch_end  \t|  3.7664e-05     \t|  0.0030131      \n",
      "on_train_end        \t|  0.0020422      \t|  0.0020422      \n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "   | Name       | Type        | Params\n",
      "--------------------------------------------\n",
      "0  | model      | MLP6144     | 3 M   \n",
      "1  | model.fc   | Sequential  | 3 M   \n",
      "2  | model.fc.0 | BatchNorm1d | 12 K  \n",
      "3  | model.fc.1 | Linear      | 3 M   \n",
      "4  | model.fc.2 | ReLU        | 0     \n",
      "5  | model.fc.3 | Dropout     | 0     \n",
      "6  | model.fc.4 | BatchNorm1d | 1 K   \n",
      "7  | model.fc.5 | Linear      | 65 K  \n",
      "8  | model.fc.6 | ReLU        | 0     \n",
      "9  | model.fc.7 | Dropout     | 0     \n",
      "10 | model.fc.8 | BatchNorm1d | 256   \n",
      "11 | model.fc.9 | Linear      | 2 K   \n",
      "Epoch 0: loss/val reached 1.32370 (best 1.32370), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=00-loss_val=1.31.ckpt as top 3\n",
      "Epoch 1: loss/val reached 1.35659 (best 1.32370), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=01-loss_val=1.35.ckpt as top 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss/val reached 1.34252 (best 1.32370), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=02-loss_val=1.35.ckpt as top 3\n",
      "Epoch 3: loss/val reached 1.34033 (best 1.32370), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=03-loss_val=1.34.ckpt as top 3\n",
      "Epoch 4: loss/val was not in top 3\n",
      "Epoch 5: loss/val reached 1.32594 (best 1.32370), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=05-loss_val=1.33.ckpt as top 3\n",
      "Epoch 6: loss/val reached 1.31711 (best 1.31711), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=06-loss_val=1.32.ckpt as top 3\n",
      "Epoch 7: loss/val reached 1.30467 (best 1.30467), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=07-loss_val=1.30.ckpt as top 3\n",
      "Epoch 8: loss/val reached 1.30763 (best 1.30467), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=08-loss_val=1.31.ckpt as top 3\n",
      "Epoch 9: loss/val reached 1.27339 (best 1.27339), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=09-loss_val=1.27.ckpt as top 3\n",
      "Epoch 10: loss/val reached 1.27351 (best 1.27339), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=10-loss_val=1.27.ckpt as top 3\n",
      "Epoch 11: loss/val reached 1.26112 (best 1.26112), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=11-loss_val=1.26.ckpt as top 3\n",
      "Epoch 12: loss/val was not in top 3\n",
      "Epoch 13: loss/val was not in top 3\n",
      "Epoch 14: loss/val was not in top 3\n",
      "Epoch 15: loss/val was not in top 3\n",
      "Epoch 16: loss/val was not in top 3\n",
      "Epoch 17: loss/val was not in top 3\n",
      "Epoch 18: loss/val was not in top 3\n",
      "Epoch 19: loss/val reached 1.23719 (best 1.23719), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=19-loss_val=1.23.ckpt as top 3\n",
      "Epoch 20: loss/val was not in top 3\n",
      "Epoch 21: loss/val was not in top 3\n",
      "Epoch 22: loss/val was not in top 3\n",
      "Epoch 23: loss/val was not in top 3\n",
      "Epoch 24: loss/val was not in top 3\n",
      "Epoch 25: loss/val was not in top 3\n",
      "Epoch 26: loss/val reached 1.26438 (best 1.23719), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=26-loss_val=1.25.ckpt as top 3\n",
      "Epoch 27: loss/val was not in top 3\n",
      "Epoch 28: loss/val reached 1.24843 (best 1.23719), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=28-loss_val=1.27.ckpt as top 3\n",
      "Epoch 29: loss/val was not in top 3\n",
      "Epoch 30: loss/val was not in top 3\n",
      "Epoch 31: loss/val was not in top 3\n",
      "Epoch 32: loss/val reached 1.22166 (best 1.22166), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=32-loss_val=1.22.ckpt as top 3\n",
      "Epoch 33: loss/val was not in top 3\n",
      "Epoch 34: loss/val was not in top 3\n",
      "Epoch 35: loss/val was not in top 3\n",
      "Epoch 36: loss/val was not in top 3\n",
      "Epoch 37: loss/val reached 1.24120 (best 1.22166), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=37-loss_val=1.24.ckpt as top 3\n",
      "Epoch 38: loss/val was not in top 3\n",
      "Epoch 39: loss/val was not in top 3\n",
      "Epoch 40: loss/val was not in top 3\n",
      "Epoch 41: loss/val was not in top 3\n",
      "Epoch 42: loss/val was not in top 3\n",
      "Epoch 43: loss/val was not in top 3\n",
      "Epoch 44: loss/val was not in top 3\n",
      "Epoch 45: loss/val was not in top 3\n",
      "Epoch 46: loss/val was not in top 3\n",
      "Epoch 47: loss/val was not in top 3\n",
      "Epoch 48: loss/val reached 1.22461 (best 1.22166), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=48-loss_val=1.23.ckpt as top 3\n",
      "Epoch 49: loss/val was not in top 3\n",
      "Epoch 50: loss/val was not in top 3\n",
      "Epoch 51: loss/val was not in top 3\n",
      "Epoch 52: loss/val was not in top 3\n",
      "Epoch 53: loss/val was not in top 3\n",
      "Epoch 54: loss/val was not in top 3\n",
      "Epoch 55: loss/val was not in top 3\n",
      "Epoch 56: loss/val was not in top 3\n",
      "Epoch 57: loss/val was not in top 3\n",
      "Epoch 58: loss/val was not in top 3\n",
      "Epoch 59: loss/val was not in top 3\n",
      "Epoch 60: loss/val was not in top 3\n",
      "Epoch 61: loss/val was not in top 3\n",
      "Epoch 62: loss/val reached 1.23044 (best 1.22166), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-01.12.2020-01.54.52/openl3-6144-mlp-MIXUP-alpha=0.4/version_0/checkpoints/epoch=62-loss_val=1.24.ckpt as top 3\n",
      "Epoch 63: loss/val was not in top 3\n",
      "Epoch 64: loss/val was not in top 3\n",
      "Epoch 65: loss/val was not in top 3\n",
      "Epoch 66: loss/val was not in top 3\n",
      "Epoch 67: loss/val was not in top 3\n",
      "Epoch 68: loss/val was not in top 3\n",
      "Epoch 69: loss/val was not in top 3\n",
      "Epoch 70: loss/val was not in top 3\n",
      "Epoch 71: loss/val was not in top 3\n",
      "Epoch 72: loss/val was not in top 3\n",
      "Epoch 73: loss/val was not in top 3\n",
      "Epoch 74: loss/val was not in top 3\n",
      "Epoch 75: loss/val was not in top 3\n",
      "Epoch 76: loss/val was not in top 3\n",
      "Epoch 77: loss/val was not in top 3\n",
      "Epoch 78: loss/val was not in top 3\n",
      "Epoch 79: loss/val was not in top 3\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_fit_start        \t|  2.0167e-05     \t|  2.0167e-05     \n",
      "on_train_start      \t|  0.018109       \t|  0.018109       \n",
      "on_epoch_start      \t|  0.0028157      \t|  0.22526        \n",
      "on_train_epoch_start\t|  1.3371e-05     \t|  0.0010697      \n",
      "get_train_batch     \t|  0.023343       \t|  1404.3         \n",
      "on_batch_start      \t|  4.072e-05      \t|  2.4497         \n",
      "on_train_batch_start\t|  1.9913e-05     \t|  1.198          \n",
      "training_step_end   \t|  0.00012362     \t|  7.4371         \n",
      "model_forward       \t|  0.039718       \t|  2389.5         \n",
      "model_backward      \t|  0.0061261      \t|  368.55         \n",
      "on_after_backward   \t|  2.8804e-05     \t|  1.7329         \n",
      "optimizer_step      \t|  0.051798       \t|  3116.2         \n",
      "on_batch_end        \t|  3.2111e-05     \t|  1.9318         \n",
      "on_train_batch_end  \t|  0.0021927      \t|  131.91         \n",
      "on_validation_start \t|  0.025148       \t|  2.0119         \n",
      "on_validation_epoch_start\t|  2.9295e-05     \t|  0.0023436      \n",
      "on_validation_batch_start\t|  4.0137e-05     \t|  0.47201        \n",
      "validation_step_end \t|  4.5485e-05     \t|  0.53491        \n",
      "on_validation_batch_end\t|  0.0013536      \t|  15.918         \n",
      "on_validation_epoch_end\t|  0.00012181     \t|  0.0097446      \n",
      "on_validation_end   \t|  0.030596       \t|  2.4477         \n",
      "on_epoch_end        \t|  0.00012841     \t|  0.010273       \n",
      "on_train_epoch_end  \t|  4.1248e-05     \t|  0.0032998      \n",
      "on_train_end        \t|  0.0019845      \t|  0.0019845      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture cap\n",
    "import traceback \n",
    "import pandas as pd\n",
    "\n",
    "scoreboard = []\n",
    "for exp in exp_dicts:\n",
    "    print(100*'-', '\\n', 100*'-')\n",
    "    try:\n",
    "        results = run_trial(exp)\n",
    "    except:\n",
    "        print(f'exp: {exp[\"name\"]} failed.')\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "        results = {'error': True, 'done': False}\n",
    "        \n",
    "    score = dict(exp)\n",
    "    score.update(results)\n",
    "    scoreboard.append(score)\n",
    "    \n",
    "scoreboard_df = pd.DataFrame(scoreboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n"
     ]
    }
   ],
   "source": [
    "%store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreboard_df.to_csv(os.path.join(log_dir, 'scoreboard.csv'))\n",
    "with open(os.path.join(log_dir, 'output.txt'),  'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
