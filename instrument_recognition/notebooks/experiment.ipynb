{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Instrument Detection Models\n",
    "\n",
    "11/30/2020\n",
    "\n",
    "Evaluation Metrics: F1 score, Expected Calibration Error (ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define paths to datamodules \n",
    "dm_paths = {\n",
    "    'audio': \n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED/splits-85-15-REMAPPED', \n",
    "    \n",
    "    'embeddings-512': \n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED-EMBEDDINGS-512/splits-85-15-REMAPPED', \n",
    "\n",
    "    'embeddings-6144':\n",
    "    '/home/hugo/CHONK/data/mdb-hop-0.25-chunk-1-AUGMENTED-EMBEDDINGS-6144/splits-85-15-REMAPPED'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a run_trial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from instrument_recognition.task import InstrumentDetectionTask, train_instrument_detection_model\n",
    "from instrument_recognition.models.zoo import load_model\n",
    "from instrument_recognition.datasets import load_datamodule\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "def run_trial(exp_dict, test_only=False):\n",
    "\n",
    "    # load the datamodule\n",
    "    print(f'loading datamodule...')\n",
    "    dm = load_datamodule(path_to_data=exp_dict['path_to_data'], \n",
    "                         batch_size=exp_dict['batch_size'], \n",
    "                         num_workers=exp_dict['num_workers'],\n",
    "                         use_embeddings=exp_dict['use_embeddings'])\n",
    "    \n",
    "    # get classlist and number of classes\n",
    "    classlist = dm.get_classes()\n",
    "    num_output_units = len(classlist)\n",
    "    print(f'classlist is: {classlist}')\n",
    "\n",
    "    # load model\n",
    "    print(f'loading model...')\n",
    "    model = load_model(model_name=exp_dict['model_name'], \n",
    "                       output_units=num_output_units, \n",
    "                       dropout=exp_dict['dropout'])\n",
    "    \n",
    "    # build task\n",
    "    print(f'building task...')\n",
    "    task = InstrumentDetectionTask(model, dm, \n",
    "                            max_epochs=exp_dict['max_epochs'],\n",
    "                            learning_rate=exp_dict['learning_rate'], \n",
    "                            weighted_cross_entropy=exp_dict['weighted_cross_entropy'], \n",
    "                            mixup=exp_dict['mixup'],\n",
    "                            mixup_alpha=exp_dict['mixup_alpha'], \n",
    "                            log_epoch_metrics=True)\n",
    "    \n",
    "    # run train fn and get back test results\n",
    "    print(f'running task')\n",
    "    result = train_instrument_detection_model(task, \n",
    "                                    name=exp_dict['name'], \n",
    "                                    version=exp_dict['version'], \n",
    "                                    gpuid=exp_dict['gpuid'], \n",
    "                                    max_epochs=exp_dict['max_epochs'],\n",
    "                                    random_seed=exp_dict['random_seed'], \n",
    "                                    log_dir=exp_dict['log_dir'],\n",
    "                                    test_only=test_only,\n",
    "                                    **exp_dict['trainer_kwargs'])\n",
    "\n",
    "    # save exp_dict to yaml file for easy reloading\n",
    "    with open(os.path.join(exp['log_dir'], 'exp_dict.yaml'), 'w') as f:\n",
    "        yaml.dump(exp_dict, f)\n",
    "    \n",
    "    result = result[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define fixed hyperparameters\n",
    "\n",
    "we won't change these (except for the batch size in raw audio models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "now = datetime.datetime.now().strftime(\"%d.%m.%Y\")\n",
    "log_dir = os.path.join('logs', f'experiment-{now}')\n",
    "\n",
    "# define experiment\n",
    "FIXED = dict(batch_size=128*3, num_workers=20, learning_rate=3e-4,\n",
    "             weighted_cross_entropy=True, dropout=0.5, random_seed=20, \n",
    "             max_epochs=80, log_dir=log_dir,  version=0,  gpuid=-1,\n",
    "             trainer_kwargs={}) \n",
    "    \n",
    "def make_trial(trial_dict):\n",
    "    \"\"\" creates a dict with fixed hyperparams\n",
    "    and then adds trial_dict on top\n",
    "    \"\"\"\n",
    "    exp_dict = dict(FIXED) \n",
    "    exp_dict.update(trial_dict)\n",
    "    return exp_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [\n",
    "    dict(name='openl3-mlp-ERM',\n",
    "    path_to_data=dm_paths['embeddings-6144'],\n",
    "    use_embeddings= True, \n",
    "    model_name='mlp-6144',\n",
    "    mixup=False,\n",
    "    mixup_alpha=0), \n",
    "    \n",
    "    dict(name='finetuned-mlp-ERM', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='openl3mlp-6144', \n",
    "     mixup=False, \n",
    "     mixup_alpha=0,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8)),\n",
    "    \n",
    "    dict(name='baseline-mlp-ERM', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='baseline-6144', \n",
    "     mixup=False, \n",
    "     mixup_alpha=0,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8)),\n",
    "    \n",
    "    dict(name='openl3-mlp-MIXUP-alpha=0.2',\n",
    "    path_to_data=dm_paths['embeddings-6144'],\n",
    "    use_embeddings= True, \n",
    "    model_name='mlp-6144',\n",
    "    mixup=True,\n",
    "    mixup_alpha=0.2),\n",
    "    \n",
    "    dict(name='baseline-mlp-MIXUP-alpha=0.2', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='baseline-6144', \n",
    "     mixup=True, \n",
    "     mixup_alpha=0.2,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8)),\n",
    "    \n",
    "    dict(name='finetuned-mlp-MIXUP-alpha=0.2', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='openl3mlp-6144', \n",
    "     mixup=True, \n",
    "     mixup_alpha=0.2,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8)),\n",
    "    \n",
    "    # MODELS WITH MIXUP (ALPHA = 0.4)\n",
    "    dict(name='openl3-mlp-MIXUP-alpha=0.4',\n",
    "        path_to_data=dm_paths['embeddings-6144'],\n",
    "        use_embeddings= True, \n",
    "        model_name='mlp-6144',\n",
    "        mixup=True,\n",
    "        mixup_alpha=0.4), \n",
    "\n",
    "    dict(name='baseline-mlp-MIXUP-alpha=0.4', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='baseline-6144', \n",
    "     mixup=True, \n",
    "     mixup_alpha=0.4,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8)),\n",
    "    \n",
    "    dict(name='finetuned-mlp-MIXUP-alpha=0.4', \n",
    "     path_to_data=dm_paths['audio'], \n",
    "     batch_size=32*3,\n",
    "     use_embeddings=False, \n",
    "     model_name='openl3mlp-6144', \n",
    "     mixup=True, \n",
    "     mixup_alpha=0.4,\n",
    "     trainer_kwargs=dict(accumulate_grad_batches=8))\n",
    "]\n",
    "trials = {t['name']: make_trial(t) for t in trials}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train models!! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openl3-mlp-ERM\n",
      "finetuned-mlp-ERM\n",
      "baseline-mlp-ERM\n",
      "openl3-mlp-MIXUP-alpha=0.2\n",
      "baseline-mlp-MIXUP-alpha=0.2\n",
      "finetuned-mlp-MIXUP-alpha=0.2\n",
      "openl3-mlp-MIXUP-alpha=0.4\n",
      "baseline-mlp-MIXUP-alpha=0.4\n",
      "finetuned-mlp-MIXUP-alpha=0.4\n"
     ]
    }
   ],
   "source": [
    "# run me too see what trials I can run\n",
    "for k in trials:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "run_trial(trials['openl3-mlp-ERM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "run_trial(trials['openl3-mlp-MIXUP-alpha=0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "run_trial(trials['openl3-mlp-MIXUP-alpha=0.4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading datamodule...\n",
      "medley db path: /home/hugo/data/medleydb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/lab/venv/lib/python3.6/site-packages/medleydb/__init__.py:65: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n",
      "/home/hugo/lab/venv/lib/python3.6/site-packages/medleydb/__init__.py:73: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train entries: 288692\n",
      "val entries: 56020\n",
      "classlist is: ['acoustic guitar', 'auxiliary percussion', 'brass section', 'cello', 'clean electric guitar', 'distorted electric guitar', 'double bass', 'drum set', 'electric bass', 'female singer', 'male singer', 'oboe', 'piano', 'synthesizer', 'tack piano', 'trumpet', 'vibraphone', 'viola', 'violin', 'vocalists']\n",
      "loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "INFO:lightning:Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building task...\n",
      "running task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/lab/venv/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning:\n",
      "\n",
      "\n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "\n",
      "INFO:lightning:\n",
      "   | Name                                      | Type            | Params\n",
      "-------------------------------------------------------------------------------\n",
      "0  | model                                     | OpenL3MLP       | 12 M  \n",
      "1  | model.openl3                              | OpenL3Embedding | 9 M   \n",
      "2  | model.openl3.filters                      | Melspectrogram  | 4 M   \n",
      "3  | model.openl3.filters.conv1d_real          | Conv1d          | 2 M   \n",
      "4  | model.openl3.filters.conv1d_imag          | Conv1d          | 2 M   \n",
      "5  | model.openl3.filters.freq2mel             | Linear          | 262 K \n",
      "6  | model.openl3.openl3                       | OpenL3Mel128    | 4 M   \n",
      "7  | model.openl3.openl3.batch_normalization_1 | BatchNorm2d     | 2     \n",
      "8  | model.openl3.openl3.conv2d_1              | Conv2d          | 640   \n",
      "9  | model.openl3.openl3.batch_normalization_2 | BatchNorm2d     | 128   \n",
      "10 | model.openl3.openl3.conv2d_2              | Conv2d          | 36 K  \n",
      "11 | model.openl3.openl3.batch_normalization_3 | BatchNorm2d     | 128   \n",
      "12 | model.openl3.openl3.conv2d_3              | Conv2d          | 73 K  \n",
      "13 | model.openl3.openl3.batch_normalization_4 | BatchNorm2d     | 256   \n",
      "14 | model.openl3.openl3.conv2d_4              | Conv2d          | 147 K \n",
      "15 | model.openl3.openl3.batch_normalization_5 | BatchNorm2d     | 256   \n",
      "16 | model.openl3.openl3.conv2d_5              | Conv2d          | 295 K \n",
      "17 | model.openl3.openl3.batch_normalization_6 | BatchNorm2d     | 512   \n",
      "18 | model.openl3.openl3.conv2d_6              | Conv2d          | 590 K \n",
      "19 | model.openl3.openl3.batch_normalization_7 | BatchNorm2d     | 512   \n",
      "20 | model.openl3.openl3.conv2d_7              | Conv2d          | 1 M   \n",
      "21 | model.openl3.openl3.batch_normalization_8 | BatchNorm2d     | 1 K   \n",
      "22 | model.openl3.openl3.audio_embedding_layer | Conv2d          | 2 M   \n",
      "23 | model.openl3.openl3.maxpool               | MaxPool2d       | 0     \n",
      "24 | model.openl3.flatten                      | Flatten         | 0     \n",
      "25 | model.mlp                                 | MLP6144         | 3 M   \n",
      "26 | model.mlp.fc                              | Sequential      | 3 M   \n",
      "27 | model.mlp.fc.0                            | BatchNorm1d     | 12 K  \n",
      "28 | model.mlp.fc.1                            | Linear          | 3 M   \n",
      "29 | model.mlp.fc.2                            | ReLU            | 0     \n",
      "30 | model.mlp.fc.3                            | Dropout         | 0     \n",
      "31 | model.mlp.fc.4                            | BatchNorm1d     | 1 K   \n",
      "32 | model.mlp.fc.5                            | Linear          | 65 K  \n",
      "33 | model.mlp.fc.6                            | ReLU            | 0     \n",
      "34 | model.mlp.fc.7                            | Dropout         | 0     \n",
      "35 | model.mlp.fc.8                            | BatchNorm1d     | 256   \n",
      "36 | model.mlp.fc.9                            | Linear          | 2 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test tube created git tag: tt_baseline-mlp-ERM_v0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7fdf153e4548bdbc46c079176a7bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/lab/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning:\n",
      "\n",
      "Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:Epoch 0: loss/val reached 1.31725 (best 1.31725), saving model to /home/hugo/lab/mono_music_sed/instrument_recognition/notebooks/logs/experiment-03.12.2020/baseline-mlp-ERM/version_0/checkpoints/epoch=00-loss_val=1.32.ckpt as top 3\n"
     ]
    }
   ],
   "source": [
    "run_trial(trials['baseline-mlp-ERM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(trials['baseline-mlp-MIXUP-alpha=0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(trials['baseline-mlp-MIXUP-alpha=0.4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(trials['finetuned-mlp-ERM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(trials['finetuned-mlp-MIXUP-alpha=0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(trials['finetuned-mlp-MIXUP-alpha=0.4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test models :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback \n",
    "import pandas as pd\n",
    "\n",
    "scoreboard = []\n",
    "for exp in exp_dicts:\n",
    "    print(100*'-', '\\n', 100*'-')\n",
    "    try:\n",
    "        if not exp['done']:\n",
    "            results = run_trial(exp)\n",
    "            exp['done'] = True\n",
    "        else:\n",
    "            print(f'skipping {exp[\"name\"]}')\n",
    "    except:\n",
    "        print(f'exp: {exp[\"name\"]} failed.')\n",
    "        traceback.print_exc(limit=None, file=None, chain=True)\n",
    "        results = {'error': True}\n",
    "        \n",
    "    score = dict(exp)\n",
    "    score.update(results)\n",
    "    scoreboard.append(score)\n",
    "    \n",
    "scoreboard_df = pd.DataFrame(scoreboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scoreboard_df.to_csv(os.path.join(log_dir, 'scoreboard.csv'))\n",
    "with open(os.path.join(log_dir, 'output.txt'),  'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
